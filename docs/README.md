# ToDAM Ticket System   <!-- omit in toc -->

The frontend with gradio and combined with the API endpoints for the ticket system.

## Table of Contents   <!-- omit in toc -->
- [Developing Requirements](#developing-requirements)
- [Required Dependencies](#required-dependencies)
  - [Build `venv` for **MacOS**](#build-venv-for-macos)
  - [Build `venv` for **Windows**](#build-venv-for-windows)
  - [Run web app](#run-web-app)
- [Deployment](#deployment)
  - [Build the docker image](#build-the-docker-image)
  - [Deploy to AWS Lambda Function with AWS CDK](#deploy-to-aws-lambda-function-with-aws-cdk)
- [Project Structure](#project-structure)
  - [`app/`](#app)
    - [`app/cases/`](#appcases)
    - [`app/controllers/`](#appcontrollers)
    - [`app/infra/`](#appinfra)
    - [`app/views/`](#appviews)
  - [`docs/`](#docs)
  - [`scripts/`](#scripts)
- [Functions and Features](#functions-and-features)
  - [`app/infa/web/router.py`](#appinfawebrouterpy)
  - [Elements for the gradio app.](#elements-for-the-gradio-app)
    - [Blocks](#blocks)
    - [Header](#header)
    - [Refresh Button](#refresh-button)
    - [Log Segment ID Dropdown](#log-segment-id-dropdown)
  - [Past Model Output](#past-model-output)
    - [Example Response](#example-response)
    - [Method to process the Response](#method-to-process-the-response)
  - [Chat History Component](#chat-history-component)

## Developing Requirements

Python version `python3.11` or later with [`poetry`](https://python-poetry.org/) to manage the dependencies.

> [!IMPORTANT]
> If you have not installed `poetry`, please install it by following the [official guide](https://python-poetry.org/docs/#installation)

## Required Dependencies

- `gradio = "^4.31.0"`
- `uvicorn = "^0.29.0"`

### Build `venv` for **MacOS**
```shell
$ python3.11 -m venv venv
$ source venv/bin/activate
$ poetry install
$ rm -rf venv     # remove the venv
```

### Build `venv` for **Windows**
```shell
$ pip install virtualenv
$ virtualenv venv
$ venv\Scripts\activate
$ poetry install
$ rmdir /s venv     # remove the venv
```

### Run web app

Edit the `.env` file with your own token. Also need to follow the mode of the web app.

```shell
$ cp .env.example .env.<MODE>
```

```shell
# Ticket System Part
DEPARTMENT_ID="MSP_ID"

# API Endpoint Part
SUBMIT_TICKET_API_URL="DEPLOYED_SUBMIT_TICKET_API_URL"
LIST_LOG_SEGMENT_API_URL="DEPLOYED_LIST_LOG_SEGMENT_API_URL"
LIST_CHAT_HISTORY_API_URL="DEPLOYED_LIST_CHAT_HISTORY_API_URL"
BEDROCK_API_URL="DEPLOYED_BEDROCK_API_URL"

# AWS CDK Part
CDK_DEFAULT_ACCOUNT="YOUR_AWS_CDK_DEFAULT_ACCOUNT"
CDK_DEFAULT_REGION="YOUR_AWS_CDK_DEFAULT_REGION"
```

Run the web app with the following command.
```shell
# run the web app in development mode
$ python app.py --port 8080 --dev
# run the web app in test mode
$ python app.py --port 8080 --test
# run the web app in production mode
$ python app.py --port 8080 --prod

# Also you can customize the port number
$ python app.py --port 8081 --dev
```

> [!NOTE]
> If you want to run the app with the `uvicorn` server, so that you can design your own API and **reload** the app, you can run the following command.
> ```shell
> $ ./scripts/run.sh
> 
> # or
> $ uvicorn app.main:app --host 0.0.0.0 --port 8080 --reload
> ```
>
> This will use the `.env` as the default configuration file.

## Deployment

with `docker` installed, you can build and run the docker image.

### Build the docker image

```shell
$ docker build -t todam-ticket-system:<TAG_NAME> .

$ docker run -p 8080:8080 todam-ticket-system:<TAG_NAME>
```

### Deploy to AWS Lambda Function with AWS CDK

With the AWS CDK, you can deploy the gradio app to the AWS Lambda function. [^1]

```shell
$ cdk bootstrap
$ cdk deploy
```

## Project Structure

```shell
todam-ticket-system/
â”œâ”€â”€ app/
â”œâ”€â”€ docs/
â”œâ”€â”€ scripts/
â”œâ”€â”€ .env
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ LICENSE
â”œâ”€â”€ poetry.lock
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

### `app/`

```shell
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ cases/
â”‚   â”œâ”€â”€ controllers/
â”‚   â”œâ”€â”€ infra/
â”‚   â”œâ”€â”€ views/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ main.py
```

#### `app/cases/`

```shell
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ cases/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ chat_history.py
â”‚   â”‚   â”œâ”€â”€ segment.py
â”‚   â”‚   â”œâ”€â”€ submit.py
â”‚   â”‚   â””â”€â”€ ticket_summarized.py
```

#### `app/controllers/`

```shell
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ controllers/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ mock_ticket.py
```

#### `app/infra/`

```shell
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ infra/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ db/
â”‚   â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ web/
â”‚   â”‚   â”‚   â”‚   __init__.py
â”‚   â”‚   â”‚   â””â”€â”€ router.py
```

#### `app/views/`

```shell
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ views/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”‚   ...     # TODO
â”‚   â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ dashboard.py
```

### `docs/`

```shell
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ README.md
```

### `scripts/`

```shell
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ run.sh
```

## Functions and Features

### `app/infa/web/router.py`

To mount the gradio app to the FastAPI, you can use the following code. Also include the mock ticket routes.

```python
import gradio as gr
from fastapi import FastAPI

from app.views.dashboard import build_playground
from app.controllers.mock_ticket import mock_ticket_routes


def setup_routers(app: FastAPI) -> None:
    gr.mount_gradio_app(app, build_playground(), path="/playground")
    
    app.include_router(mock_ticket_routes)
```

### Elements for the gradio app.

#### Blocks

The outermost container that can contain multiple `Component`.

```python
# app/views/dashboard.py
with gr.Blocks(
    title='ToDAM Ticket System',
) as demo:
```

#### Header

The header component that displays the title.

```python
# app/views/dashboard.py
gr.HTML(
    "<h1 align=center>ToDAM Ticket System</h1>"
)
```

#### Refresh Button

Once we launch the app, we need to fetch the data from the API endpoint. We can use the refresh button as a trigger to fetch the data. (Gradio needs the event to trigger the function; it does not have the `onload` event. Therefore, we need to use the refresh button to fetch the data.)

```python
# app/views/dashboard.py
refresh_btn = gr.Button(
    variant="secondary",
    value="ğŸ”„ Refresh Log Segments Records",
)
```

Once the user clicks the refresh button, it fetches the data from the API endpoint.

```python
# app/views/dashboard.py
refresh_btn.click(
    fn=get_segments,
    inputs=[log_segment_id],
    outputs=[log_segment_id],
)
```

The case of the refresh button is to fetch the data from the API endpoint. Then we will use the log segment ID to fetch the chat history. And make it to the format that we can display on the gradio app.

```python
# app/cases/segment.py
def get_segments(
        log_segment: gr.Dropdown) -> gr.Dropdown:
    """
    Get segments from the API

    Args:
        log_segment (gr.Dropdown): Dropdown object

    Returns:
        gr.Dropdown: Dropdown object
    """
    _ = load_dotenv(find_dotenv())
    list_log_segment_api_url: str = os.environ['LIST_LOG_SEGMENT_API_URL']

    payload = {}
    headers = {}

    response = requests.request(
        method="GET", url=list_log_segment_api_url, headers=headers, data=payload
    )
    if response.status_code == 200:
        data = json.loads(response.text)

    segment_ids = [segment["segment_id"] for segment in data["segments"]]
    segment_names = [segment["segment_name"] for segment in data["segments"]]
    group_ids = [segment["group_id"] for segment in data["segments"]]

    log_segment = gr.Dropdown(
        label="ğŸš˜ Log Segment Records (ID)",
        info="Select a Record Segment to summerize with ğŸ‘‡ğŸ»",
        value=segment_ids[0],
        choices=segment_ids,
        interactive=True,
        multiselect=None,
        # visible=False,
    )

    return log_segment
```

#### Log Segment ID Dropdown

The dropdown component that allows the user to select the log segment ID. And it fetches the data from the API endpoint.

```python
# app/views/dashboard.py
log_segment_id = gr.Dropdown(
    label="ğŸš˜ Log Segment Records (ID)",
    info="Select a Record Segment to summerize with ğŸ‘‡ğŸ»",
    interactive=True,
    multiselect=None,
    # visible=False,
)
```

Once the user selects the log segment ID, it fetches the data from the API endpoint.

```python
# app/views/dashboard.py
log_segment_id.change(
    fn=get_row_chat_history,
    inputs=log_segment_id,
    outputs=[row_chat_history, prev_summerized_ticket_content],
)
```

If the user selects the log segment ID, it fetches the chat history from the API endpoint. And ready to call the Azure ML API to get the summerized content.

```python
# app/cases/chat_history.py

# TODO:
# 1. éœ€è¦æœ‰èƒ½åŠ›å» Handle Dropdown æ˜¯ç©ºçš„æƒ…æ³ -> å…·é«”è¦å›å‚³ä»€éº¼çµ¦ gradio
def get_row_chat_history(
        log_segment_subject: str) -> tuple[tuple[str, str], str]:
    _ = load_dotenv(find_dotenv())
    list_chat_history_api_url: str = os.environ['LIST_CHAT_HISTORY_API_URL']
    url = f"{list_chat_history_api_url}/messages?segment_id={log_segment_subject}"

    headers = {}
    payload = {}

    response = requests.request("GET", url, headers=headers, data=payload)
    if response.status_code == 200:
        data = json.loads(response.text)

    messages = data["messages"]

    # print(data)

    row_chat_history = []

    for message in messages:
        if message["user_type"] == "Client":
            row_chat_history.append((None, message["content"]))
        elif message["user_type"] == "TAM":
            row_chat_history.append((message["content"], None))

    prev_summerized_ticket_content = """<img src="https://img.pikbest.com/png-images/20190918/cartoon-snail-loading-loading-gif-animation_2734139.png!f305cw" alt="cartoon snail loading" />"""

    return row_chat_history, prev_summerized_ticket_content

def process_tickets(tickets):
    processed_tickets = []
    for ticket in tickets:
        role = ticket.get("Role")
        description = ticket.get("Description")
        if role == "Client":
            processed_tickets.append((None, description))
        elif role == "TAM":
            processed_tickets.append((description, None))
    return processed_tickets
```

### Past Model Output

```python
def get_summarized_ticket_content(
        log_segment: gr.Dropdown, row_chat_history: gr.Chatbot) -> tuple[str, str]:
    _ = load_dotenv(find_dotenv())
    azure_ml_deployed_url : str = os.environ['AZURE_ML_DEPLOYED_URL']
    azure_ml_token        : str = os.environ['AZURE_ML_TOKEN']
    azure_model_deployment: str = os.environ['AZURE_MODEL_DEPLOYMENT']

    result = []
    current_user_type = None

    for item in row_chat_history:
        tam_message, client_message = item
        if tam_message:
            current_user_type = "TAM"
            content = tam_message
        elif client_message:
            current_user_type = "Client"
            content = client_message
        else:
            # Skip recording messages
            continue
        
        result.append({
            "user_type": current_user_type,
            "content": content
        })

    headers = {
        'azureml-model-deployment': azure_model_deployment,
        'authorization': f"Bearer {azure_ml_token}"
    }
    payload = str(result)

    response: Response = requests.request(
        "POST", azure_ml_deployed_url, 
        headers=headers, 
        data=payload
    )

    if response.status_code == 200:
        data: dict = json.loads(response.text)
    else:
        return "Error: Something went wrong with the API"

    result: dict = json.loads(data["result"])    # data["result"] è£¡é¢æ˜¯ä¸€å€‹ JSON æ ¼å¼çš„å­—ä¸²
    # transcript = result["transcript"]
    case_id = log_segment
    # case_id = result["caseId"]
    subject = result["subject"]

    transcript_output = ""
    for item in result['transcript']:
        transcript_output += f"<blockquote><h3>Submitted by {item['Submitted by']}</h3>Content: {item['content']}</blockquote>\n"

    subject_output = f"<h1>Subject: {subject}</h1>"
    summerized_ticket_content = f"<div>\n<h3>Case ID: {case_id}</h3>\n{transcript_output}\n</div>"
```

#### Example Response

```json
{
    "result": "{\n  \"subject\": \"Ticket regarding account upgrade\",\n  \"caseId\": null,\n  \"startDate\": null,\n  \"transcript\": [\n    {\n      \"Submitted by\": \"Customer\",\n      \"content\": \"Hello, I am having trouble upgrading my account to the premium plan. Every time I try to upgrade, it gives me an error message.\"\n    },\n    {\n      \"Submitted by\": \"TAM\",\n      \"content\": \"I apologize for the inconvenience. Can you please provide me with the exact error message you are receiving when trying to upgrade?\"\n    },\n    {\n      \"Submitted by\": \"Customer\",\n      \"content\": \"The error message says 'Payment Failed. Please check your payment details and try again.' But I have checked my payment details and they are correct.\"\n    },\n    {\n      \"Submitted by\": \"TAM\",\n      \"content\": \"Thank you for providing the error message. Let me investigate this issue further for you. Can you please provide me with your account username or email address?\"\n    },\n    {\n      \"Submitted by\": \"Customer\",\n      \"content\": \"My account username is john123.\"\n    },\n    {\n      \"Submitted by\": \"TAM\",\n      \"content\": \"Thank you for the information. I will look into your account and see what might be causing the payment failure. Please bear with me for a moment.\"\n    }\n  ]\n}"
}
```

#### Method to process the Response

1. Extract `result` from the response. (The `result` is a JSON string.)

```python
if response.status_code == 200:
    data: dict = json.loads(response.text)
else:
    return "Error: Something went wrong with the API"

result: dict = json.loads(data["result"])    # data["result"] è£¡é¢æ˜¯ä¸€å€‹ JSON æ ¼å¼çš„å­—ä¸²
```

2. Extract the `subject` from the `result`.

```python
subject = result["subject"]
```

3. Extract the `transcript` from the `result` and get the `Submitted by` and `content`.

```python
transcript_output = ""
for item in result['transcript']:
    transcript_output += f"<blockquote><h3>Submitted by {item['Submitted by']}</h3>Content: {item['content']}</blockquote>\n"
```

### Chat History Component

```python
(None, "Customer sayings")
("TAM sayings", None)
```



```json
{
    "id": "msg_016YsKtQJGV1BTkdujPsWyhh",
    "type": "message",
    "role": "assistant",
    "content": [
        {
            "type": "text",
            "text": "{\n  \"subject\": \"Azure Linux VM 504 Error and Performance Optimization\",\n  \"caseId\": null,\n  \"startDate\": null,\n  \"transcript\": [\n    {\n      \"submittedBy\": \"Client\",\n      \"content\": \"æˆ‘å€‘çš„è™›æ“¬æ©Ÿå™¨åœ¨ Azure ä¸Šé‹è¡Œï¼Œé…ç½®ç‚º Linuxï¼ŒVM ä¸–ä»£ç‚º V1ï¼Œæ¶æ§‹æ˜¯ x64ï¼Œä¼‘çœ å·²ç¦ç”¨ï¼Œå…¬å…± IP åœ°å€ç‚º 20.253.222.207ï¼ˆç¶²çµ¡æ¥å£ç‚º adam-linux580ï¼‰ï¼Œç§æœ‰ IP åœ°å€ç‚º 10.0.3.4ï¼Œè™›æ“¬ç¶²çµ¡/å­ç¶²çµ¡ç‚º adam-vnet/adam-private-1ï¼Œè¦æ¨¡ç‚ºæ¨™æº– B2sï¼ˆ2 vCPUsã€4 GiB RAMï¼‰ï¼Œç£ç›¤ç‚º adam-disk-linuxï¼ˆä¸»æ©ŸåŠ å¯†å·²ç¦ç”¨ï¼Œæœªå•Ÿç”¨ Azure ç£ç›¤åŠ å¯†ï¼‰ï¼Œå®‰å…¨é¡å‹ç‚ºæ¨™æº–ã€‚æˆ‘å€‘æœ€è¿‘é‡åˆ°äº† 504 éŒ¯èª¤ï¼Œæ‚¨èƒ½å¹«å¿™åˆ†æå•é¡Œæ‰€åœ¨å—ï¼Ÿ\"\n    },\n    {\n      \"submittedBy\": \"Client\",\n      \"content\": \"[Image URL](        https://todam-bucket-478977890696-us-east-1.s3.amazonaws.com/jpg/test_azure.png)\\nThe image shows the configuration details of a virtual machine (VM) running on a cloud platform, likely Microsoft Azure.\"\n    },\n    {\n      \"submittedBy\": \"TAM\",\n      \"content\": \"å¾ˆæŠ±æ­‰è½åˆ°æ‚¨é‡åˆ° 504 éŒ¯èª¤ã€‚é€™å¯èƒ½èˆ‡æ‚¨çš„è™›æ“¬æ©Ÿå™¨çš„æ€§èƒ½æˆ–é€£æ¥æœ‰é—œã€‚è«‹ç¢ºä¿æ‚¨çš„è™›æ“¬æ©Ÿå™¨çš„è³‡æºä½¿ç”¨åˆç†ä¸¦ä¸”æœªå—åˆ°ä»»ä½•é™åˆ¶ï¼Œç‰¹åˆ¥æ˜¯åœ¨é«˜è² è¼‰æ™‚ã€‚åŒæ™‚ï¼Œè«‹æª¢æŸ¥æ‚¨çš„ç¶²çµ¡è¨­ç½®ï¼Œç¢ºä¿é€£æ¥åˆ° Azure çš„ç¶²çµ¡ç©©å®šä¸”ç„¡é˜»ç¤™ã€‚æ‚¨å¯ä»¥æŸ¥çœ‹ Azure çš„ç›£æ§å·¥å…·ä¾†æª¢è¦–è™›æ“¬æ©Ÿå™¨çš„æ€§èƒ½æŒ‡æ¨™å’Œç¶²çµ¡ç‹€æ…‹ã€‚å¦‚æœå•é¡Œä»ç„¶å­˜åœ¨ï¼Œæ‚¨å¯èƒ½éœ€è¦é€²ä¸€æ­¥çš„èª¿æŸ¥æˆ–è¯ç¹« Azure æŠ€è¡“æ”¯æ´ä»¥ç²å¾—å”åŠ©ã€‚\"\n    },\n    {\n      \"submittedBy\": \"Client\",\n      \"content\": \"æ„Ÿè¬æ‚¨çš„å›ç­”ã€‚æˆ‘å€‘å°‡æŒ‰ç…§æ‚¨æä¾›çš„å»ºè­°ä¾†æª¢æŸ¥å’Œè§£æ±ºå•é¡Œã€‚å¦å¤–ï¼Œæˆ‘å€‘é‚„æœ‰ä¸€å€‹é—œæ–¼è™›æ“¬æ©Ÿå™¨æ€§èƒ½èª¿æ•´çš„å•é¡Œã€‚æˆ‘å€‘çš„ VM åœ¨é«˜è² è¼‰æ™‚è¡¨ç¾ä¸ä½³ï¼Œæ‚¨èƒ½æä¾›ä¸€äº›æ€§èƒ½å„ªåŒ–çš„å»ºè­°å—ï¼Ÿ\"\n    },\n    {\n      \"submittedBy\": \"TAM\",\n      \"content\": \"ç•¶è™›æ“¬æ©Ÿå™¨åœ¨é«˜è² è¼‰æ™‚è¡¨ç¾ä¸ä½³æ™‚ï¼Œæ‚¨å¯ä»¥è€ƒæ…®ä»¥ä¸‹å¹¾é»ä¾†é€²è¡Œæ€§èƒ½å„ªåŒ–ï¼šé¦–å…ˆï¼Œæª¢æŸ¥è™›æ“¬æ©Ÿå™¨çš„è³‡æºé…ç½®ï¼Œå¯èƒ½éœ€è¦å¢åŠ  vCPU å’Œ RAM ä¾†æ‡‰å°æ›´é«˜çš„è² è¼‰ï¼›å…¶æ¬¡ï¼Œå„ªåŒ–æ‡‰ç”¨ç¨‹åºå’Œæœå‹™ï¼Œç¢ºä¿å®ƒå€‘èƒ½å¤ æœ‰æ•ˆåœ°åˆ©ç”¨è™›æ“¬æ©Ÿå™¨çš„è³‡æºï¼›å¦å¤–ï¼Œå¯ä»¥è€ƒæ…®ä½¿ç”¨ Azure çš„è² è¼‰å‡è¡¡å™¨ä¾†å¹³è¡¡è² è¼‰ï¼Œå°‡æµé‡åˆ†é…åˆ°å¤šå€‹è™›æ“¬æ©Ÿå™¨ä¸Šã€‚æœ€å¾Œï¼Œç›£æ§ç³»çµ±æ€§èƒ½ä¸¦é€²è¡ŒæŒçºŒçš„å„ªåŒ–å’Œèª¿æ•´ä»¥ç¢ºä¿æœ€ä½³æ•ˆèƒ½ã€‚\"\n    }\n  ]\n}"
        }
    ],
    "model": "claude-3-sonnet-28k-20240229",
    "stop_reason": "end_turn",
    "stop_sequence": null,
    "usage": {
        "input_tokens": 1578,
        "output_tokens": 915
    }
}
```

```json
{
    "subject": "Azure Linux VM 504 Error and Performance Optimization",
    "caseId": null,
    "startDate": null,
    "transcript": [
        {
            "submittedBy": "Client",
            "content": "æˆ‘å€‘çš„è™›æ“¬æ©Ÿå™¨åœ¨ Azure ä¸Šé‹è¡Œï¼Œé…ç½®ç‚º Linuxï¼ŒVM ä¸–ä»£ç‚º V1ï¼Œæ¶æ§‹æ˜¯ x64ï¼Œä¼‘çœ å·²ç¦ç”¨ï¼Œå…¬å…± IP åœ°å€ç‚º 20.253.222.207ï¼ˆç¶²çµ¡æ¥å£ç‚º adam-linux580ï¼‰ï¼Œç§æœ‰ IP åœ°å€ç‚º 10.0.3.4ï¼Œè™›æ“¬ç¶²çµ¡/å­ç¶²çµ¡ç‚º adam-vnet/adam-private-1ï¼Œè¦æ¨¡ç‚ºæ¨™æº– B2sï¼ˆ2 vCPUsã€4 GiB RAMï¼‰ï¼Œç£ç›¤ç‚º adam-disk-linuxï¼ˆä¸»æ©ŸåŠ å¯†å·²ç¦ç”¨ï¼Œæœªå•Ÿç”¨ Azure ç£ç›¤åŠ å¯†ï¼‰ï¼Œå®‰å…¨é¡å‹ç‚ºæ¨™æº–ã€‚æˆ‘å€‘æœ€è¿‘é‡åˆ°äº† 504 éŒ¯èª¤ï¼Œæ‚¨èƒ½å¹«å¿™åˆ†æå•é¡Œæ‰€åœ¨å—ï¼Ÿ"
        },
        {
            "submittedBy": "Client",
            "content": "[Image URL](
        https://todam-bucket-478977890696-us-east-1.s3.amazonaws.com/jpg/test_azure.png)\nThe
        image shows the configuration details of a virtual machine (VM) running on a cloud platform, likely Microsoft Azure."
        },
        {
            "submittedBy": "TAM",
            "content": "å¾ˆæŠ±æ­‰è½åˆ°æ‚¨é‡åˆ° 504 éŒ¯èª¤ã€‚é€™å¯èƒ½èˆ‡æ‚¨çš„è™›æ“¬æ©Ÿå™¨çš„æ€§èƒ½æˆ–é€£æ¥æœ‰é—œã€‚è«‹ç¢ºä¿æ‚¨çš„è™›æ“¬æ©Ÿå™¨çš„è³‡æºä½¿ç”¨åˆç†ä¸¦ä¸”æœªå—åˆ°ä»»ä½•é™åˆ¶ï¼Œç‰¹åˆ¥æ˜¯åœ¨é«˜è² è¼‰æ™‚ã€‚åŒæ™‚ï¼Œè«‹æª¢æŸ¥æ‚¨çš„ç¶²çµ¡è¨­ç½®ï¼Œç¢ºä¿é€£æ¥åˆ° Azure çš„ç¶²çµ¡ç©©å®šä¸”ç„¡é˜»ç¤™ã€‚æ‚¨å¯ä»¥æŸ¥çœ‹ Azure çš„ç›£æ§å·¥å…·ä¾†æª¢è¦–è™›æ“¬æ©Ÿå™¨çš„æ€§èƒ½æŒ‡æ¨™å’Œç¶²çµ¡ç‹€æ…‹ã€‚å¦‚æœå•é¡Œä»ç„¶å­˜åœ¨ï¼Œæ‚¨å¯èƒ½éœ€è¦é€²ä¸€æ­¥çš„èª¿æŸ¥æˆ–è¯ç¹« Azure æŠ€è¡“æ”¯æ´ä»¥ç²å¾—å”åŠ©ã€‚"
        },
        {
            "submittedBy": "Client",
            "content": "æ„Ÿè¬æ‚¨çš„å›ç­”ã€‚æˆ‘å€‘å°‡æŒ‰ç…§æ‚¨æä¾›çš„å»ºè­°ä¾†æª¢æŸ¥å’Œè§£æ±ºå•é¡Œã€‚å¦å¤–ï¼Œæˆ‘å€‘é‚„æœ‰ä¸€å€‹é—œæ–¼è™›æ“¬æ©Ÿå™¨æ€§èƒ½èª¿æ•´çš„å•é¡Œã€‚æˆ‘å€‘çš„ VM åœ¨é«˜è² è¼‰æ™‚è¡¨ç¾ä¸ä½³ï¼Œæ‚¨èƒ½æä¾›ä¸€äº›æ€§èƒ½å„ªåŒ–çš„å»ºè­°å—ï¼Ÿ"
        },
        {
            "submittedBy": "TAM",
            "content": "ç•¶è™›æ“¬æ©Ÿå™¨åœ¨é«˜è² è¼‰æ™‚è¡¨ç¾ä¸ä½³æ™‚ï¼Œæ‚¨å¯ä»¥è€ƒæ…®ä»¥ä¸‹å¹¾é»ä¾†é€²è¡Œæ€§èƒ½å„ªåŒ–ï¼šé¦–å…ˆï¼Œæª¢æŸ¥è™›æ“¬æ©Ÿå™¨çš„è³‡æºé…ç½®ï¼Œå¯èƒ½éœ€è¦å¢åŠ  vCPU å’Œ RAM ä¾†æ‡‰å°æ›´é«˜çš„è² è¼‰ï¼›å…¶æ¬¡ï¼Œå„ªåŒ–æ‡‰ç”¨ç¨‹åºå’Œæœå‹™ï¼Œç¢ºä¿å®ƒå€‘èƒ½å¤ æœ‰æ•ˆåœ°åˆ©ç”¨è™›æ“¬æ©Ÿå™¨çš„è³‡æºï¼›å¦å¤–ï¼Œå¯ä»¥è€ƒæ…®ä½¿ç”¨ Azure çš„è² è¼‰å‡è¡¡å™¨ä¾†å¹³è¡¡è² è¼‰ï¼Œå°‡æµé‡åˆ†é…åˆ°å¤šå€‹è™›æ“¬æ©Ÿå™¨ä¸Šã€‚æœ€å¾Œï¼Œç›£æ§ç³»çµ±æ€§èƒ½ä¸¦é€²è¡ŒæŒçºŒçš„å„ªåŒ–å’Œèª¿æ•´ä»¥ç¢ºä¿æœ€ä½³æ•ˆèƒ½ã€‚"
        }
    ]
}
```


[^1]: [Serverless Machine Learning Applications with Hugging Face Gradio and AWS Lambda](https://www.philschmid.de/serverless-gradio)
[^2]: [philschmid/serverless-machine-learning/gradio-aws-lambda-transformers](https://github.com/philschmid/serverless-machine-learning/tree/main/gradio-aws-lambda-transformers)


